//! Markdown Report Generation
//!
//! Utilities for generating markdown-formatted benchmark reports
//! compatible with the canonical benchmark interface.

use super::BenchmarkResult;
use chrono::Utc;

/// Generate a markdown summary report from benchmark results.
///
/// # Arguments
///
/// * `results` - Vector of benchmark results to summarize
///
/// # Returns
///
/// A formatted markdown string suitable for writing to summary.md
pub fn generate_summary(results: &[BenchmarkResult]) -> String {
    let now = Utc::now();
    let successful = results.iter().filter(|r| r.is_success()).count();
    let failed = results.len() - successful;

    let mut md = String::new();

    // Header
    md.push_str("# Policy Engine Benchmark Results\n\n");
    md.push_str(&format!("**Generated:** {}\n\n", now.format("%Y-%m-%d %H:%M:%S UTC")));
    md.push_str(&format!("**Total Benchmarks:** {}\n", results.len()));
    md.push_str(&format!("**Successful:** {}\n", successful));
    md.push_str(&format!("**Failed:** {}\n\n", failed));

    // Summary Table
    md.push_str("## Summary\n\n");
    md.push_str("| Target ID | Duration (ms) | Throughput | Status |\n");
    md.push_str("|-----------|---------------|------------|--------|\n");

    for result in results {
        let duration = result
            .duration_ms()
            .map(|d| format!("{:.2}", d))
            .unwrap_or_else(|| "N/A".to_string());

        let throughput = result
            .throughput()
            .map(|t| format!("{:.2} ops/s", t))
            .unwrap_or_else(|| "N/A".to_string());

        let status = if result.is_success() { "✅" } else { "❌" };

        md.push_str(&format!(
            "| {} | {} | {} | {} |\n",
            result.target_id, duration, throughput, status
        ));
    }

    md.push_str("\n");

    // Detailed Results
    md.push_str("## Detailed Results\n\n");

    for result in results {
        md.push_str(&format!("### {}\n\n", result.target_id));
        md.push_str(&format!("**Timestamp:** {}\n\n", result.timestamp.format("%Y-%m-%d %H:%M:%S UTC")));
        md.push_str("**Metrics:**\n\n");
        md.push_str("```json\n");
        md.push_str(&serde_json::to_string_pretty(&result.metrics).unwrap_or_default());
        md.push_str("\n```\n\n");
    }

    // Footer
    md.push_str("---\n\n");
    md.push_str("*Generated by policy-engine-benchmarks - Canonical Benchmark Interface*\n");

    md
}

/// Generate a brief one-line summary for each result.
pub fn generate_brief_summary(results: &[BenchmarkResult]) -> String {
    results
        .iter()
        .map(|r| {
            let status = if r.is_success() { "OK" } else { "FAIL" };
            let duration = r.duration_ms().map(|d| format!("{:.2}ms", d)).unwrap_or_default();
            format!("[{}] {} {}", status, r.target_id, duration)
        })
        .collect::<Vec<_>>()
        .join("\n")
}

#[cfg(test)]
mod tests {
    use super::*;
    use serde_json::json;

    #[test]
    fn test_generate_summary() {
        let results = vec![
            BenchmarkResult::new(
                "policy_evaluation",
                json!({
                    "duration_ms": 42.5,
                    "throughput": 23529.41,
                    "success": true
                }),
            ),
            BenchmarkResult::failed("condition_parsing", "Timeout"),
        ];

        let summary = generate_summary(&results);

        assert!(summary.contains("# Policy Engine Benchmark Results"));
        assert!(summary.contains("policy_evaluation"));
        assert!(summary.contains("condition_parsing"));
        assert!(summary.contains("✅"));
        assert!(summary.contains("❌"));
    }

    #[test]
    fn test_brief_summary() {
        let results = vec![
            BenchmarkResult::new("test1", json!({"duration_ms": 10.0, "success": true})),
            BenchmarkResult::failed("test2", "Error"),
        ];

        let brief = generate_brief_summary(&results);

        assert!(brief.contains("[OK] test1 10.00ms"));
        assert!(brief.contains("[FAIL] test2"));
    }
}
